{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Person Counter: Prediction\n",
    "This notebook contains code for prediction using pre-trained models. It stores the output in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"MOT16\"\n",
    "VIDEO_SEQ = 10 # Range 01 to 14\n",
    "MODEL_ID = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "#from matplotlib import pyplot as plt # Commented because of warning that matplot lib is already loaded\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../obj_det/utils/visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/ioloop.py\", line 1008, in start\n",
      "    self._run_callback(self._callbacks.popleft())\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2724, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/IPython/core/events.py\", line 74, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/IPython/core/pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../obj_det/\")\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "from utils import per_image_evaluation as img_eval_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variables\n",
    "\n",
    "We use models from the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Models used in paper\n",
    "ALL_MODEL = ['ssd_mobilenet_v1_coco_2017_11_17' #0\n",
    "    ,'ssd_inception_v2_coco_2017_11_17' #1\n",
    "    ,'rfcn_resnet101_coco_2018_01_28' #2\n",
    "    ,'faster_rcnn_resnet101_coco_2018_01_28' #3\n",
    "    ,'faster_rcnn_inception_v2_coco_2018_01_28' #4\n",
    "]\n",
    "\n",
    "MODEL_NAME = ALL_MODEL[MODEL_ID]\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "OD_DIR = '../obj_det'\n",
    "\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_CKPT = os.path.join(OD_DIR, PATH_TO_CKPT)\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "PATH_TO_LABELS = os.path.join(OD_DIR, PATH_TO_LABELS)\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'name': u'person'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from normalized coordinates to original image coordinates\n",
    "def denormalise_box(box, image_size):\n",
    "    box[:,0] = box[:,0] * image_size[1]\n",
    "    box[:,1] = box[:,1] * image_size[0]\n",
    "    box[:,2] = box[:,2] * image_size[1]\n",
    "    box[:,3] = box[:,3] * image_size[0]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "```\n",
    "MOT16\n",
    "/train\n",
    "  /MOT16-02\n",
    "    /seqinfo.ini\n",
    "    /img1\n",
    "    /gt\n",
    "        gt.txt\n",
    "\n",
    "PersonCounter\n",
    " /Output\n",
    "   /ModelA\n",
    "        prediction                 // Pickle file of groundtruth and prediction\n",
    "        /Image                     // Folder of images with GT and predicted BB\n",
    "        evaluate                   // Results of evalute\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if VIDEO_SEQ in [2,4,5,9,10,11,13]:\n",
    "    VIDEO_SEQ = str(VIDEO_SEQ).zfill(2)\n",
    "    PATH_TO_DATABASE = '../MOT16/train/MOT16-' + VIDEO_SEQ + '/'\n",
    "else:\n",
    "    VIDEO_SEQ = str(VIDEO_SEQ).zfill(2)\n",
    "    PATH_TO_DATABASE = '../MOT16/test/MOT16-' + VIDEO_SEQ + '/'\n",
    "\n",
    "PATH_TO_IMAGES_DIR = PATH_TO_DATABASE + 'img1/'\n",
    "PATH_TO_ANNOTATIONS_DIR = PATH_TO_DATABASE + '/gt/gt.txt'\n",
    "\n",
    "PATH_TO_OUTPUT_DIR = 'Output/'\n",
    "PATH_TO_PREDICTION_DIR = os.path.join(PATH_TO_OUTPUT_DIR, MODEL_NAME + '_MOT16_' + VIDEO_SEQ) # Output/Model_MOT16_01\n",
    "PREDICTION_PKL_FILE = os.path.join(PATH_TO_PREDICTION_DIR, \"prediction\")\n",
    "FILTERED_PKL_FILE = os.path.join(PATH_TO_PREDICTION_DIR, \"prediction_filtered\") # Filtered to only person class\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "# Store results to Output/Model directory\n",
    "if not os.path.exists(PATH_TO_PREDICTION_DIR):\n",
    "    os.makedirs(PATH_TO_PREDICTION_DIR)\n",
    "    os.makedirs(os.path.join(PATH_TO_PREDICTION_DIR,\"Image\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_np : np array of the image\n",
    "# prediction : prediction dictionary for the image\n",
    "# groundtruth : groundtruth dictionary for the image\n",
    "def visualize_image(image_np, prediction=None, groundtruth=None):\n",
    "    if prediction != None:\n",
    "        # Plot the prediction\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          prediction['detection_boxes'],\n",
    "          prediction['detection_classes'],\n",
    "          prediction['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=prediction.get('detection_masks'),\n",
    "          use_normalized_coordinates=False,\n",
    "          min_score_thresh=0.30,\n",
    "          line_thickness=8)\n",
    "    \n",
    "    if groundtruth != None:\n",
    "        # Plot the ground truth\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          groundtruth['groundtruth_boxes'],\n",
    "          groundtruth['groundtruth_classes'],\n",
    "          None,\n",
    "          category_index,\n",
    "          instance_masks=groundtruth.get('detection_masks'),\n",
    "          use_normalized_coordinates=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path : file name with extension E.g: 00010.jpg\n",
    "# prediction : prediction dictionary of the image\n",
    "def drawBB(image_path, prediction):\n",
    "    # Visualization of the results of a detection.\n",
    "    original_image_path = os.path.join(PATH_TO_IMAGES_DIR, image_path)   \n",
    "    marked_image_path = os.path.join(PATH_TO_PREDICTION_DIR, 'Image')\n",
    "    marked_image_path = os.path.join(marked_image_path, image_path) \n",
    "\n",
    "    image = Image.open(original_image_path)\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Update the image with predicted and groundtruth BB\n",
    "    visualize_image(image_np, groundtruth=prediction)\n",
    "    # visualize_image(image_np, prediction=prediction)    \n",
    "    im = Image.fromarray(image_np)\n",
    "    IMAGE_FILE = os.path.join(marked_image_path)\n",
    "    #print \"Save file in\" + IMAGE_FILE\n",
    "    im.save(IMAGE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract groundtruth from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gt_for_single_image(image_id):\n",
    "    annotation_path = os.path.join(PATH_TO_TEST_ANNOTATIONS_DIR, '{}.xml'.format(image_id))\n",
    "    \n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    groundtruth_dict = {}\n",
    "    gt_bbs = []\n",
    "    cat_id = []\n",
    "    cat_label = []\n",
    "    \n",
    "    for object_node in root.iterfind('object'):\n",
    "        # Extract boundary box from XML files\n",
    "        for bb in object_node.iterfind('bndbox'):\n",
    "            gt_bb = []\n",
    "            for val in ['ymin', 'xmin', 'ymax', 'xmax']:\n",
    "                gt_bb.append(float(bb.find(val).text))\n",
    "            gt_bbs.append(gt_bb)\n",
    "\n",
    "        # Extract ground truth category\n",
    "        child = object_node.find('name')\n",
    "        cat_label.append(child.text)\n",
    "        # Hardcoded as of now :/\n",
    "        if child.text == 'cow':\n",
    "            cat_id.append(21)\n",
    "        elif child.text == 'dog':\n",
    "            cat_id.append(18)\n",
    "        # print(child.text)\n",
    "\n",
    "    # Extract size\n",
    "    groundtruth_dict['size'] = [int(root.find('size/width').text), int(root.find('size/height').text)]\n",
    "    # Dog is category 18 / Todo update\n",
    "    groundtruth_dict['num_detections'] = len(gt_bbs)\n",
    "    groundtruth_dict['original_boxes'] = gt_bbs\n",
    "    groundtruth_dict['groundtruth_boxes'] = np.array(gt_bbs, dtype=\"float32\")\n",
    "    groundtruth_dict['groundtruth_classes'] = np.array(cat_id) # np.full([len(gt_bbs)], 18)\n",
    "    groundtruth_dict['groundtruth_class_labels'] = np.array(cat_label) # np.full([len(gt_bbs)], 'dog')\n",
    "    \n",
    "    return groundtruth_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV text-file containing one object instance per line. Each line must contain 10 values: \n",
    "# <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>, <conf>, <x>, <y>, <z> \n",
    "# All frame numbers, target IDs and bounding boxes are 1-based\n",
    "# Frame number is image number without leading 0\n",
    "# Person ID is <id>\n",
    "\n",
    "def extract_gt():\n",
    "    gt = 0\n",
    "    with open(PATH_TO_ANNOTATIONS_DIR, 'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            print ', '.join(row)\n",
    "            groundtruth = {}\n",
    "            gt_bbs = []\n",
    "            cat_label = []\n",
    "            \n",
    "            # For each BB in each image\n",
    "            gt_bb = []\n",
    "            gt_bb.append( float(row[3]) + float(row[5])  ) # ymin # bb_top - bb_height\n",
    "            gt_bb.append( float(row[2]) ) # xmin # bb_left\n",
    "            gt_bb.append( float(row[3]) ) # ymax # bb_top\n",
    "            gt_bb.append( float(row[2]) + float(row[4]) ) # xmax # bb_left + bb_width\n",
    "            \n",
    "            gt_bbs.append(gt_bb)\n",
    "            cat_label.append(str(category_index[1]['name']))\n",
    "            print cat_label\n",
    "            groundtruth['filename'] = row[1].zfill(6) + '.jpg'\n",
    "            groundtruth['groundtruth_boxes'] = np.array(gt_bbs, dtype=\"float32\")\n",
    "            groundtruth['groundtruth_classes'] = np.array(cat_label)\n",
    "\n",
    "            return groundtruth\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching algo\n",
    "Data association via IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given two frames, match the detection to groundtruth.\n",
    "In decreasing sorted order, assign the GT if IoU > IoU threshold\n",
    "Filter detection score < score threshold\n",
    "\n",
    "    Args:\n",
    "      detected_boxes: A numpy array of shape [N, 4] representing detected box coordinates\n",
    "      detected_scores: A 1-d numpy array of length N representing classification score\n",
    "      groundtruth_boxes: A numpy array of shape [M, 4] representing ground truth box coordinates\n",
    "\n",
    "    Returns:\n",
    "      scores: A numpy array representing the detection scores, sorted and filtered.\n",
    "      max_overlap_gt_ids: A numpy array indicating the detection's corresponding groundtruth box\n",
    "      tp_fp_labels: a boolean numpy array indicating whether a detection is a true positive.\n",
    "      is_gt_box_detected: Indicates if a ground truth box is detected \n",
    "\"\"\"\n",
    "def twoFrameMatching(pie, detected_boxes, detected_scores, groundtruth_boxes):\n",
    "    # Default value false\n",
    "    num_groundtruth_boxes = np.shape(groundtruth_boxes)[0]\n",
    "    groundtruth_is_group_of_list = np.zeros(num_groundtruth_boxes, dtype=bool)\n",
    "\n",
    "    # Compute IoU for every detection and groundtruth pair\n",
    "    # Detection with score < score threshold are ignored. Rest are sorted.\n",
    "    (iou, _, scores, num_detected_boxes) = pie._get_overlaps_and_scores_box_mode(\n",
    "               detected_boxes=detected_boxes,\n",
    "               detected_scores=detected_scores,\n",
    "               groundtruth_boxes=groundtruth_boxes,\n",
    "               groundtruth_is_group_of_list=groundtruth_is_group_of_list)\n",
    "    \n",
    "    # If no GT value then all detection are false positive\n",
    "    if groundtruth_boxes.size == 0:\n",
    "        #return scores, np.zeros(num_detected_boxes, dtype=bool)\n",
    "        print \"All FP\"\n",
    "    \n",
    "    # Is ith detection a True positive\n",
    "    tp_fp_labels = np.zeros(num_detected_boxes, dtype=bool)\n",
    "\n",
    "    # Tp-fp evaluation for non-group of boxes (if any).\n",
    "    if iou.shape[1] > 0:\n",
    "        # For each detection, the best matched GT \n",
    "        max_overlap_gt_ids = np.argmax(iou, axis=1)\n",
    "        is_gt_box_detected = np.zeros(iou.shape[1], dtype=bool)\n",
    "        for i in range(num_detected_boxes):\n",
    "            gt_id = max_overlap_gt_ids[i]\n",
    "            if iou[i, gt_id] >= pie.matching_iou_threshold and not is_gt_box_detected[gt_id]:\n",
    "                tp_fp_labels[i] = True\n",
    "                is_gt_box_detected[gt_id] = True\n",
    "\n",
    "    # Detection matched to\n",
    "    for i in range(num_detected_boxes):\n",
    "        print \"Dt\", scores[i], \"GT\", max_overlap_gt_ids[i], \"\", tp_fp_labels[i]\n",
    "    for i in range(num_groundtruth_boxes):\n",
    "        print \"GT\", i, bool(is_gt_box_detected[i])\n",
    "\n",
    "    return scores, max_overlap_gt_ids, tp_fp_labels, is_gt_box_detected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groundtruth_classes = 1\n",
    "matching_iou_threshold = 0.5\n",
    "nms_iou_threshold = 1.0\n",
    "nms_max_output_boxes = 10000\n",
    "\n",
    "# Per image evaluation\n",
    "pie = img_eval_util.PerImageEvaluation(\n",
    "    num_groundtruth_classes, matching_iou_threshold, nms_iou_threshold,\n",
    "    nms_max_output_boxes)\n",
    "\n",
    "# Dataset\n",
    "detected_boxes = np.array([[0, 0, 1, 1], [0, 0, 2, 2], [0, 0, 3, 3]], dtype=float)\n",
    "detected_scores = np.array([0.6, 0.8, 0.5], dtype=float) # Original\n",
    "\n",
    "groundtruth_boxes = np.array([[0, 0, 1, 1], [0, 0, 10, 10]], dtype=float)\n",
    "\n",
    "#twoFrameMatching(pie, detected_boxes, detected_scores, groundtruth_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes']\n",
      "[ 1  3  6  7  8 10 15 27 28 31 33]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "with open(PREDICTION_PKL_FILE,'rb') as fd:\n",
    "    ev_data = pickle.load(fd)\n",
    "    groundtruth = ev_data['000001']\n",
    "    print [i for i in groundtruth.keys()]\n",
    "    # Keep only person\n",
    "    print np.unique(groundtruth['detection_classes'])\n",
    "    idx = groundtruth['detection_classes'][groundtruth['detection_classes'] == 1]\n",
    "    groundtruth['num_detections'] = np.count_nonzero(idx)\n",
    "    groundtruth['detection_boxes'] = groundtruth['detection_boxes'][idx]\n",
    "    groundtruth['detection_scores'] = groundtruth['detection_boxes'][idx]\n",
    "    groundtruth['detection_classes'] = groundtruth['detection_classes'][idx]\n",
    "\n",
    "# Add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from object_detection.utils import np_box_list\n",
    "# from object_detection.utils import np_box_list_ops\n",
    "\n",
    "# detected_boxlist = np_box_list.BoxList(detected_boxes)\n",
    "# print detected_boxlist\n",
    "# detected_boxlist.add_field('scores', detected_scores)\n",
    "\n",
    "# detected_boxlist = np_box_list_ops.non_max_suppression(detected_boxlist, pie.nms_max_output_boxes, pie.nms_iou_threshold)\n",
    "\n",
    "# print detected_scores\n",
    "# scores = detected_boxlist.get_field('scores')\n",
    "# print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter prediction to only person class\n",
    "def filter_prediction():\n",
    "    print(PREDICTION_PKL_FILE)\n",
    "    with open(PREDICTION_PKL_FILE,'rb') as fd:\n",
    "        ev_data = pickle.load(fd)\n",
    "        # Need to sequentially analyse\n",
    "        for i in range(1,655):\n",
    "            # File name without extension\n",
    "            image_id = str(i).zfill(6)\n",
    "            prediction = ev_data[image_id]\n",
    "            # Person class = 1 in COCO dataset\n",
    "            idx = prediction['detection_classes'][prediction['detection_classes'] == 1]\n",
    "            prediction['num_detections'] = np.count_nonzero(idx)\n",
    "            prediction['detection_boxes'] = prediction['detection_boxes'][idx]\n",
    "            prediction['detection_scores'] = prediction['detection_boxes'][idx]\n",
    "            prediction['detection_classes'] = prediction['detection_classes'][idx]\n",
    "            print \"Image\", image_id, \"dt\", groundtruth['num_detections']\n",
    "        # Store in pickle\n",
    "        with open(FILTERED_PKL_FILE,'wb') as fd2:\n",
    "            pickle.dump(ev_data, fd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_data={}\n",
    "# Evaluate the prediction\n",
    "def evaluate():\n",
    "    print(PREDICTION_PKL_FILE)\n",
    "    with open(PREDICTION_PKL_FILE,'rb') as fd:\n",
    "        ev_data = pickle.load(fd)\n",
    "        # Need to sequentially analyse\n",
    "#         for i in range(1,655):\n",
    "#             # File name without extension\n",
    "#             image_id = str(i).zfill(6)\n",
    "#             prediction = ev_data[image_id]\n",
    "            # Plot the BB on image\n",
    "            # drawBB(image_path, prediction)\n",
    "    return ev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output/ssd_inception_v2_coco_2017_11_17_MOT16_10/prediction\n",
      "Image 000001 dt 61\n",
      "Image 000002 dt 61\n",
      "Image 000003 dt 61\n",
      "Image 000004 dt 61\n",
      "Image 000005 dt 61\n",
      "Image 000006 dt 61\n",
      "Image 000007 dt 61\n",
      "Image 000008 dt 61\n",
      "Image 000009 dt 61\n",
      "Image 000010 dt 61\n",
      "Image 000011 dt 61\n",
      "Image 000012 dt 61\n",
      "Image 000013 dt 61\n",
      "Image 000014 dt 61\n",
      "Image 000015 dt 61\n",
      "Image 000016 dt 61\n",
      "Image 000017 dt 61\n",
      "Image 000018 dt 61\n",
      "Image 000019 dt 61\n",
      "Image 000020 dt 61\n",
      "Image 000021 dt 61\n",
      "Image 000022 dt 61\n",
      "Image 000023 dt 61\n",
      "Image 000024 dt 61\n",
      "Image 000025 dt 61\n",
      "Image 000026 dt 61\n",
      "Image 000027 dt 61\n",
      "Image 000028 dt 61\n",
      "Image 000029 dt 61\n",
      "Image 000030 dt 61\n",
      "Image 000031 dt 61\n",
      "Image 000032 dt 61\n",
      "Image 000033 dt 61\n",
      "Image 000034 dt 61\n",
      "Image 000035 dt 61\n",
      "Image 000036 dt 61\n",
      "Image 000037 dt 61\n",
      "Image 000038 dt 61\n",
      "Image 000039 dt 61\n",
      "Image 000040 dt 61\n",
      "Image 000041 dt 61\n",
      "Image 000042 dt 61\n",
      "Image 000043 dt 61\n",
      "Image 000044 dt 61\n",
      "Image 000045 dt 61\n",
      "Image 000046 dt 61\n",
      "Image 000047 dt 61\n",
      "Image 000048 dt 61\n",
      "Image 000049 dt 61\n",
      "Image 000050 dt 61\n",
      "Image 000051 dt 61\n",
      "Image 000052 dt 61\n",
      "Image 000053 dt 61\n",
      "Image 000054 dt 61\n",
      "Image 000055 dt 61\n",
      "Image 000056 dt 61\n",
      "Image 000057 dt 61\n",
      "Image 000058 dt 61\n",
      "Image 000059 dt 61\n",
      "Image 000060 dt 61\n",
      "Image 000061 dt 61\n",
      "Image 000062 dt 61\n",
      "Image 000063 dt 61\n",
      "Image 000064 dt 61\n",
      "Image 000065 dt 61\n",
      "Image 000066 dt 61\n",
      "Image 000067 dt 61\n",
      "Image 000068 dt 61\n",
      "Image 000069 dt 61\n",
      "Image 000070 dt 61\n",
      "Image 000071 dt 61\n",
      "Image 000072 dt 61\n",
      "Image 000073 dt 61\n",
      "Image 000074 dt 61\n",
      "Image 000075 dt 61\n",
      "Image 000076 dt 61\n",
      "Image 000077 dt 61\n",
      "Image 000078 dt 61\n",
      "Image 000079 dt 61\n",
      "Image 000080 dt 61\n",
      "Image 000081 dt 61\n",
      "Image 000082 dt 61\n",
      "Image 000083 dt 61\n",
      "Image 000084 dt 61\n",
      "Image 000085 dt 61\n",
      "Image 000086 dt 61\n",
      "Image 000087 dt 61\n",
      "Image 000088 dt 61\n",
      "Image 000089 dt 61\n",
      "Image 000090 dt 61\n",
      "Image 000091 dt 61\n",
      "Image 000092 dt 61\n",
      "Image 000093 dt 61\n",
      "Image 000094 dt 61\n",
      "Image 000095 dt 61\n",
      "Image 000096 dt 61\n",
      "Image 000097 dt 61\n",
      "Image 000098 dt 61\n",
      "Image 000099 dt 61\n",
      "Image 000100 dt 61\n",
      "Image 000101 dt 61\n",
      "Image 000102 dt 61\n",
      "Image 000103 dt 61\n",
      "Image 000104 dt 61\n",
      "Image 000105 dt 61\n",
      "Image 000106 dt 61\n",
      "Image 000107 dt 61\n",
      "Image 000108 dt 61\n",
      "Image 000109 dt 61\n",
      "Image 000110 dt 61\n",
      "Image 000111 dt 61\n",
      "Image 000112 dt 61\n",
      "Image 000113 dt 61\n",
      "Image 000114 dt 61\n",
      "Image 000115 dt 61\n",
      "Image 000116 dt 61\n",
      "Image 000117 dt 61\n",
      "Image 000118 dt 61\n",
      "Image 000119 dt 61\n",
      "Image 000120 dt 61\n",
      "Image 000121 dt 61\n",
      "Image 000122 dt 61\n",
      "Image 000123 dt 61\n",
      "Image 000124 dt 61\n",
      "Image 000125 dt 61\n",
      "Image 000126 dt 61\n",
      "Image 000127 dt 61\n",
      "Image 000128 dt 61\n",
      "Image 000129 dt 61\n",
      "Image 000130 dt 61\n",
      "Image 000131 dt 61\n",
      "Image 000132 dt 61\n",
      "Image 000133 dt 61\n",
      "Image 000134 dt 61\n",
      "Image 000135 dt 61\n",
      "Image 000136 dt 61\n",
      "Image 000137 dt 61\n",
      "Image 000138 dt 61\n",
      "Image 000139 dt 61\n",
      "Image 000140 dt 61\n",
      "Image 000141 dt 61\n",
      "Image 000142 dt 61\n",
      "Image 000143 dt 61\n",
      "Image 000144 dt 61\n",
      "Image 000145 dt 61\n",
      "Image 000146 dt 61\n",
      "Image 000147 dt 61\n",
      "Image 000148 dt 61\n",
      "Image 000149 dt 61\n",
      "Image 000150 dt 61\n",
      "Image 000151 dt 61\n",
      "Image 000152 dt 61\n",
      "Image 000153 dt 61\n",
      "Image 000154 dt 61\n",
      "Image 000155 dt 61\n",
      "Image 000156 dt 61\n",
      "Image 000157 dt 61\n",
      "Image 000158 dt 61\n",
      "Image 000159 dt 61\n",
      "Image 000160 dt 61\n",
      "Image 000161 dt 61\n",
      "Image 000162 dt 61\n",
      "Image 000163 dt 61\n",
      "Image 000164 dt 61\n",
      "Image 000165 dt 61\n",
      "Image 000166 dt 61\n",
      "Image 000167 dt 61\n",
      "Image 000168 dt 61\n",
      "Image 000169 dt 61\n",
      "Image 000170 dt 61\n",
      "Image 000171 dt 61\n",
      "Image 000172 dt 61\n",
      "Image 000173 dt 61\n",
      "Image 000174 dt 61\n",
      "Image 000175 dt 61\n",
      "Image 000176 dt 61\n",
      "Image 000177 dt 61\n",
      "Image 000178 dt 61\n",
      "Image 000179 dt 61\n",
      "Image 000180 dt 61\n",
      "Image 000181 dt 61\n",
      "Image 000182 dt 61\n",
      "Image 000183 dt 61\n",
      "Image 000184 dt 61\n",
      "Image 000185 dt 61\n",
      "Image 000186 dt 61\n",
      "Image 000187 dt 61\n",
      "Image 000188 dt 61\n",
      "Image 000189 dt 61\n",
      "Image 000190 dt 61\n",
      "Image 000191 dt 61\n",
      "Image 000192 dt 61\n",
      "Image 000193 dt 61\n",
      "Image 000194 dt 61\n",
      "Image 000195 dt 61\n",
      "Image 000196 dt 61\n",
      "Image 000197 dt 61\n",
      "Image 000198 dt 61\n",
      "Image 000199 dt 61\n",
      "Image 000200 dt 61\n",
      "Image 000201 dt 61\n",
      "Image 000202 dt 61\n",
      "Image 000203 dt 61\n",
      "Image 000204 dt 61\n",
      "Image 000205 dt 61\n",
      "Image 000206 dt 61\n",
      "Image 000207 dt 61\n",
      "Image 000208 dt 61\n",
      "Image 000209 dt 61\n",
      "Image 000210 dt 61\n",
      "Image 000211 dt 61\n",
      "Image 000212 dt 61\n",
      "Image 000213 dt 61\n",
      "Image 000214 dt 61\n",
      "Image 000215 dt 61\n",
      "Image 000216 dt 61\n",
      "Image 000217 dt 61\n",
      "Image 000218 dt 61\n",
      "Image 000219 dt 61\n",
      "Image 000220 dt 61\n",
      "Image 000221 dt 61\n",
      "Image 000222 dt 61\n",
      "Image 000223 dt 61\n",
      "Image 000224 dt 61\n",
      "Image 000225 dt 61\n",
      "Image 000226 dt 61\n",
      "Image 000227 dt 61\n",
      "Image 000228 dt 61\n",
      "Image 000229 dt 61\n",
      "Image 000230 dt 61\n",
      "Image 000231 dt 61\n",
      "Image 000232 dt 61\n",
      "Image 000233 dt 61\n",
      "Image 000234 dt 61\n",
      "Image 000235 dt 61\n",
      "Image 000236 dt 61\n",
      "Image 000237 dt 61\n",
      "Image 000238 dt 61\n",
      "Image 000239 dt 61\n",
      "Image 000240 dt 61\n",
      "Image 000241 dt 61\n",
      "Image 000242 dt 61\n",
      "Image 000243 dt 61\n",
      "Image 000244 dt 61\n",
      "Image 000245 dt 61\n",
      "Image 000246 dt 61\n",
      "Image 000247 dt 61\n",
      "Image 000248 dt 61\n",
      "Image 000249 dt 61\n",
      "Image 000250 dt 61\n",
      "Image 000251 dt 61\n",
      "Image 000252 dt 61\n",
      "Image 000253 dt 61\n",
      "Image 000254 dt 61\n",
      "Image 000255 dt 61\n",
      "Image 000256 dt 61\n",
      "Image 000257 dt 61\n",
      "Image 000258 dt 61\n",
      "Image 000259 dt 61\n",
      "Image 000260 dt 61\n",
      "Image 000261 dt 61\n",
      "Image 000262 dt 61\n",
      "Image 000263 dt 61\n",
      "Image 000264 dt 61\n",
      "Image 000265 dt 61\n",
      "Image 000266 dt 61\n",
      "Image 000267 dt 61\n",
      "Image 000268 dt 61\n",
      "Image 000269 dt 61\n",
      "Image 000270 dt 61\n",
      "Image 000271 dt 61\n",
      "Image 000272 dt 61\n",
      "Image 000273 dt 61\n",
      "Image 000274 dt 61\n",
      "Image 000275 dt 61\n",
      "Image 000276 dt 61\n",
      "Image 000277 dt 61\n",
      "Image 000278 dt 61\n",
      "Image 000279 dt 61\n",
      "Image 000280 dt 61\n",
      "Image 000281 dt 61\n",
      "Image 000282 dt 61\n",
      "Image 000283 dt 61\n",
      "Image 000284 dt 61\n",
      "Image 000285 dt 61\n",
      "Image 000286 dt 61\n",
      "Image 000287 dt 61\n",
      "Image 000288 dt 61\n",
      "Image 000289 dt 61\n",
      "Image 000290 dt 61\n",
      "Image 000291 dt 61\n",
      "Image 000292 dt 61\n",
      "Image 000293 dt 61\n",
      "Image 000294 dt 61\n",
      "Image 000295 dt 61\n",
      "Image 000296 dt 61\n",
      "Image 000297 dt 61\n",
      "Image 000298 dt 61\n",
      "Image 000299 dt 61\n",
      "Image 000300 dt 61\n",
      "Image 000301 dt 61\n",
      "Image 000302 dt 61\n",
      "Image 000303 dt 61\n",
      "Image 000304 dt 61\n",
      "Image 000305 dt 61\n",
      "Image 000306 dt 61\n",
      "Image 000307 dt 61\n",
      "Image 000308 dt 61\n",
      "Image 000309 dt 61\n",
      "Image 000310 dt 61\n",
      "Image 000311 dt 61\n",
      "Image 000312 dt 61\n",
      "Image 000313 dt 61\n",
      "Image 000314 dt 61\n",
      "Image 000315 dt 61\n",
      "Image 000316 dt 61\n",
      "Image 000317 dt 61\n",
      "Image 000318 dt 61\n",
      "Image 000319 dt 61\n",
      "Image 000320 dt 61\n",
      "Image 000321 dt 61\n",
      "Image 000322 dt 61\n",
      "Image 000323 dt 61\n",
      "Image 000324 dt 61\n",
      "Image 000325 dt 61\n",
      "Image 000326 dt 61\n",
      "Image 000327 dt 61\n",
      "Image 000328 dt 61\n",
      "Image 000329 dt 61\n",
      "Image 000330 dt 61\n",
      "Image 000331 dt 61\n",
      "Image 000332 dt 61\n",
      "Image 000333 dt 61\n",
      "Image 000334 dt 61\n",
      "Image 000335 dt 61\n",
      "Image 000336 dt 61\n",
      "Image 000337 dt 61\n",
      "Image 000338 dt 61\n",
      "Image 000339 dt 61\n",
      "Image 000340 dt 61\n",
      "Image 000341 dt 61\n",
      "Image 000342 dt 61\n",
      "Image 000343 dt 61\n",
      "Image 000344 dt 61\n",
      "Image 000345 dt 61\n",
      "Image 000346 dt 61\n",
      "Image 000347 dt 61\n",
      "Image 000348 dt 61\n",
      "Image 000349 dt 61\n",
      "Image 000350 dt 61\n",
      "Image 000351 dt 61\n",
      "Image 000352 dt 61\n",
      "Image 000353 dt 61\n",
      "Image 000354 dt 61\n",
      "Image 000355 dt 61\n",
      "Image 000356 dt 61\n",
      "Image 000357 dt 61\n",
      "Image 000358 dt 61\n",
      "Image 000359 dt 61\n",
      "Image 000360 dt 61\n",
      "Image 000361 dt 61\n",
      "Image 000362 dt 61\n",
      "Image 000363 dt 61\n",
      "Image 000364 dt 61\n",
      "Image 000365 dt 61\n",
      "Image 000366 dt 61\n",
      "Image 000367 dt 61\n",
      "Image 000368 dt 61\n",
      "Image 000369 dt 61\n",
      "Image 000370 dt 61\n",
      "Image 000371 dt 61\n",
      "Image 000372 dt 61\n",
      "Image 000373 dt 61\n",
      "Image 000374 dt 61\n",
      "Image 000375 dt 61\n",
      "Image 000376 dt 61\n",
      "Image 000377 dt 61\n",
      "Image 000378 dt 61\n",
      "Image 000379 dt 61\n",
      "Image 000380 dt 61\n",
      "Image 000381 dt 61\n",
      "Image 000382 dt 61\n",
      "Image 000383 dt 61\n",
      "Image 000384 dt 61\n",
      "Image 000385 dt 61\n",
      "Image 000386 dt 61\n",
      "Image 000387 dt 61\n",
      "Image 000388 dt 61\n",
      "Image 000389 dt 61\n",
      "Image 000390 dt 61\n",
      "Image 000391 dt 61\n",
      "Image 000392 dt 61\n",
      "Image 000393 dt 61\n",
      "Image 000394 dt 61\n",
      "Image 000395 dt 61\n",
      "Image 000396 dt 61\n",
      "Image 000397 dt 61\n",
      "Image 000398 dt 61\n",
      "Image 000399 dt 61\n",
      "Image 000400 dt 61\n",
      "Image 000401 dt 61\n",
      "Image 000402 dt 61\n",
      "Image 000403 dt 61\n",
      "Image 000404 dt 61\n",
      "Image 000405 dt 61\n",
      "Image 000406 dt 61\n",
      "Image 000407 dt 61\n",
      "Image 000408 dt 61\n",
      "Image 000409 dt 61\n",
      "Image 000410 dt 61\n",
      "Image 000411 dt 61\n",
      "Image 000412 dt 61\n",
      "Image 000413 dt 61\n",
      "Image 000414 dt 61\n",
      "Image 000415 dt 61\n",
      "Image 000416 dt 61\n",
      "Image 000417 dt 61\n",
      "Image 000418 dt 61\n",
      "Image 000419 dt 61\n",
      "Image 000420 dt 61\n",
      "Image 000421 dt 61\n",
      "Image 000422 dt 61\n",
      "Image 000423 dt 61\n",
      "Image 000424 dt 61\n",
      "Image 000425 dt 61\n",
      "Image 000426 dt 61\n",
      "Image 000427 dt 61\n",
      "Image 000428 dt 61\n",
      "Image 000429 dt 61\n",
      "Image 000430 dt 61\n",
      "Image 000431 dt 61\n",
      "Image 000432 dt 61\n",
      "Image 000433 dt 61\n",
      "Image 000434 dt 61\n",
      "Image 000435 dt 61\n",
      "Image 000436 dt 61\n",
      "Image 000437 dt 61\n",
      "Image 000438 dt 61\n",
      "Image 000439 dt 61\n",
      "Image 000440 dt 61\n",
      "Image 000441 dt 61\n",
      "Image 000442 dt 61\n",
      "Image 000443 dt 61\n",
      "Image 000444 dt 61\n",
      "Image 000445 dt 61\n",
      "Image 000446 dt 61\n",
      "Image 000447 dt 61\n",
      "Image 000448 dt 61\n",
      "Image 000449 dt 61\n",
      "Image 000450 dt 61\n",
      "Image 000451 dt 61\n",
      "Image 000452 dt 61\n",
      "Image 000453 dt 61\n",
      "Image 000454 dt 61\n",
      "Image 000455 dt 61\n",
      "Image 000456 dt 61\n",
      "Image 000457 dt 61\n",
      "Image 000458 dt 61\n",
      "Image 000459 dt 61\n",
      "Image 000460 dt 61\n",
      "Image 000461 dt 61\n",
      "Image 000462 dt 61\n",
      "Image 000463 dt 61\n",
      "Image 000464 dt 61\n",
      "Image 000465 dt 61\n",
      "Image 000466 dt 61\n",
      "Image 000467 dt 61\n",
      "Image 000468 dt 61\n",
      "Image 000469 dt 61\n",
      "Image 000470 dt 61\n",
      "Image 000471 dt 61\n",
      "Image 000472 dt 61\n",
      "Image 000473 dt 61\n",
      "Image 000474 dt 61\n",
      "Image 000475 dt 61\n",
      "Image 000476 dt 61\n",
      "Image 000477 dt 61\n",
      "Image 000478 dt 61\n",
      "Image 000479 dt 61\n",
      "Image 000480 dt 61\n",
      "Image 000481 dt 61\n",
      "Image 000482 dt 61\n",
      "Image 000483 dt 61\n",
      "Image 000484 dt 61\n",
      "Image 000485 dt 61\n",
      "Image 000486 dt 61\n",
      "Image 000487 dt 61\n",
      "Image 000488 dt 61\n",
      "Image 000489 dt 61\n",
      "Image 000490 dt 61\n",
      "Image 000491 dt 61\n",
      "Image 000492 dt 61\n",
      "Image 000493 dt 61\n",
      "Image 000494 dt 61\n",
      "Image 000495 dt 61\n",
      "Image 000496 dt 61\n",
      "Image 000497 dt 61\n",
      "Image 000498 dt 61\n",
      "Image 000499 dt 61\n",
      "Image 000500 dt 61\n",
      "Image 000501 dt 61\n",
      "Image 000502 dt 61\n",
      "Image 000503 dt 61\n",
      "Image 000504 dt 61\n",
      "Image 000505 dt 61\n",
      "Image 000506 dt 61\n",
      "Image 000507 dt 61\n",
      "Image 000508 dt 61\n",
      "Image 000509 dt 61\n",
      "Image 000510 dt 61\n",
      "Image 000511 dt 61\n",
      "Image 000512 dt 61\n",
      "Image 000513 dt 61\n",
      "Image 000514 dt 61\n",
      "Image 000515 dt 61\n",
      "Image 000516 dt 61\n",
      "Image 000517 dt 61\n",
      "Image 000518 dt 61\n",
      "Image 000519 dt 61\n",
      "Image 000520 dt 61\n",
      "Image 000521 dt 61\n",
      "Image 000522 dt 61\n",
      "Image 000523 dt 61\n",
      "Image 000524 dt 61\n",
      "Image 000525 dt 61\n",
      "Image 000526 dt 61\n",
      "Image 000527 dt 61\n",
      "Image 000528 dt 61\n",
      "Image 000529 dt 61\n",
      "Image 000530 dt 61\n",
      "Image 000531 dt 61\n",
      "Image 000532 dt 61\n",
      "Image 000533 dt 61\n",
      "Image 000534 dt 61\n",
      "Image 000535 dt 61\n",
      "Image 000536 dt 61\n",
      "Image 000537 dt 61\n",
      "Image 000538 dt 61\n",
      "Image 000539 dt 61\n",
      "Image 000540 dt 61\n",
      "Image 000541 dt 61\n",
      "Image 000542 dt 61\n",
      "Image 000543 dt 61\n",
      "Image 000544 dt 61\n",
      "Image 000545 dt 61\n",
      "Image 000546 dt 61\n",
      "Image 000547 dt 61\n",
      "Image 000548 dt 61\n",
      "Image 000549 dt 61\n",
      "Image 000550 dt 61\n",
      "Image 000551 dt 61\n",
      "Image 000552 dt 61\n",
      "Image 000553 dt 61\n",
      "Image 000554 dt 61\n",
      "Image 000555 dt 61\n",
      "Image 000556 dt 61\n",
      "Image 000557 dt 61\n",
      "Image 000558 dt 61\n",
      "Image 000559 dt 61\n",
      "Image 000560 dt 61\n",
      "Image 000561 dt 61\n",
      "Image 000562 dt 61\n",
      "Image 000563 dt 61\n",
      "Image 000564 dt 61\n",
      "Image 000565 dt 61\n",
      "Image 000566 dt 61\n",
      "Image 000567 dt 61\n",
      "Image 000568 dt 61\n",
      "Image 000569 dt 61\n",
      "Image 000570 dt 61\n",
      "Image 000571 dt 61\n",
      "Image 000572 dt 61\n",
      "Image 000573 dt 61\n",
      "Image 000574 dt 61\n",
      "Image 000575 dt 61\n",
      "Image 000576 dt 61\n",
      "Image 000577 dt 61\n",
      "Image 000578 dt 61\n",
      "Image 000579 dt 61\n",
      "Image 000580 dt 61\n",
      "Image 000581 dt 61\n",
      "Image 000582 dt 61\n",
      "Image 000583 dt 61\n",
      "Image 000584 dt 61\n",
      "Image 000585 dt 61\n",
      "Image 000586 dt 61\n",
      "Image 000587 dt 61\n",
      "Image 000588 dt 61\n",
      "Image 000589 dt 61\n",
      "Image 000590 dt 61\n",
      "Image 000591 dt 61\n",
      "Image 000592 dt 61\n",
      "Image 000593 dt 61\n",
      "Image 000594 dt 61\n",
      "Image 000595 dt 61\n",
      "Image 000596 dt 61\n",
      "Image 000597 dt 61\n",
      "Image 000598 dt 61\n",
      "Image 000599 dt 61\n",
      "Image 000600 dt 61\n",
      "Image 000601 dt 61\n",
      "Image 000602 dt 61\n",
      "Image 000603 dt 61\n",
      "Image 000604 dt 61\n",
      "Image 000605 dt 61\n",
      "Image 000606 dt 61\n",
      "Image 000607 dt 61\n",
      "Image 000608 dt 61\n",
      "Image 000609 dt 61\n",
      "Image 000610 dt 61\n",
      "Image 000611 dt 61\n",
      "Image 000612 dt 61\n",
      "Image 000613 dt 61\n",
      "Image 000614 dt 61\n",
      "Image 000615 dt 61\n",
      "Image 000616 dt 61\n",
      "Image 000617 dt 61\n",
      "Image 000618 dt 61\n",
      "Image 000619 dt 61\n",
      "Image 000620 dt 61\n",
      "Image 000621 dt 61\n",
      "Image 000622 dt 61\n",
      "Image 000623 dt 61\n",
      "Image 000624 dt 61\n",
      "Image 000625 dt 61\n",
      "Image 000626 dt 61\n",
      "Image 000627 dt 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 000628 dt 61\n",
      "Image 000629 dt 61\n",
      "Image 000630 dt 61\n",
      "Image 000631 dt 61\n",
      "Image 000632 dt 61\n",
      "Image 000633 dt 61\n",
      "Image 000634 dt 61\n",
      "Image 000635 dt 61\n",
      "Image 000636 dt 61\n",
      "Image 000637 dt 61\n",
      "Image 000638 dt 61\n",
      "Image 000639 dt 61\n",
      "Image 000640 dt 61\n",
      "Image 000641 dt 61\n",
      "Image 000642 dt 61\n",
      "Image 000643 dt 61\n",
      "Image 000644 dt 61\n",
      "Image 000645 dt 61\n",
      "Image 000646 dt 61\n",
      "Image 000647 dt 61\n",
      "Image 000648 dt 61\n",
      "Image 000649 dt 61\n",
      "Image 000650 dt 61\n",
      "Image 000651 dt 61\n",
      "Image 000652 dt 61\n",
      "Image 000653 dt 61\n",
      "Image 000654 dt 61\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filter_prediction()\n",
    "    #ev_data = evaluate()\n",
    "    print \"Done\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
