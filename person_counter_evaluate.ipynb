{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Person Counter: Prediction\n",
    "This notebook contains code for prediction using pre-trained models. It stores the output in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"MOT16\"\n",
    "VIDEO_SEQ_ID = 10 # Range 01 to 14\n",
    "MODEL_ID = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "#from matplotlib import pyplot as plt # Commented because of warning that matplot lib is already loaded\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../obj_det/utils/visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/ioloop.py\", line 1008, in start\n",
      "    self._run_callback(self._callbacks.popleft())\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2724, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/IPython/core/events.py\", line 74, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/IPython/core/pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/chrystle/anaconda2/envs/od27/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "#from pc_utils import pc_PerImageEvaluation\n",
    "import pc_utils\n",
    "sys.path.append(\"../obj_det/\")\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variables\n",
    "\n",
    "We use models from the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Models used in paper\n",
    "ALL_MODEL = ['ssd_mobilenet_v1_coco_2017_11_17' #0\n",
    "    ,'ssd_inception_v2_coco_2017_11_17' #1\n",
    "    ,'rfcn_resnet101_coco_2018_01_28' #2\n",
    "    ,'faster_rcnn_resnet101_coco_2018_01_28' #3\n",
    "    ,'faster_rcnn_inception_v2_coco_2018_01_28' #4\n",
    "]\n",
    "\n",
    "MODEL_NAME = ALL_MODEL[MODEL_ID]\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "OD_DIR = '../obj_det'\n",
    "\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_CKPT = os.path.join(OD_DIR, PATH_TO_CKPT)\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "PATH_TO_LABELS = os.path.join(OD_DIR, PATH_TO_LABELS)\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "pc_label = {} # For label marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'name': u'person'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from normalized coordinates to original image coordinates\n",
    "def denormalise_box(box, image_size):\n",
    "    box[:,0] = box[:,0] * image_size[1]\n",
    "    box[:,1] = box[:,1] * image_size[0]\n",
    "    box[:,2] = box[:,2] * image_size[1]\n",
    "    box[:,3] = box[:,3] * image_size[0]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "```\n",
    "MOT16\n",
    "/train\n",
    "  /MOT16-02\n",
    "    /seqinfo.ini\n",
    "    /img1\n",
    "    /gt\n",
    "        gt.txt\n",
    "\n",
    "PersonCounter\n",
    " /Output\n",
    "   /ModelA\n",
    "        prediction                 // Pickle file of groundtruth and prediction\n",
    "        /Image                     // Folder of images with GT and predicted BB\n",
    "        evaluate                   // Results of evalute\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageCount():\n",
    "    # Read seqinfo.ini to get seqLength=654\n",
    "    with open(PATH_TO_DATABASE + 'seqinfo.ini','rb') as fd:\n",
    "        meta = fd.read()\n",
    "        idx = meta.find('seqLength')\n",
    "        meta[idx+10:idx+13]\n",
    "        return int( meta[idx+10:idx+13] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if VIDEO_SEQ_ID in [2,4,5,9,10,11,13]:\n",
    "    VIDEO_SEQ = str(VIDEO_SEQ_ID).zfill(2)\n",
    "    PATH_TO_DATABASE = '../MOT16/train/MOT16-' + VIDEO_SEQ + '/'\n",
    "else:\n",
    "    VIDEO_SEQ = str(VIDEO_SEQ_ID).zfill(2)\n",
    "    PATH_TO_DATABASE = '../MOT16/test/MOT16-' + VIDEO_SEQ + '/'\n",
    "\n",
    "IMAGE_COUNT = getImageCount()\n",
    "\n",
    "#print IMAGE_COUNT\n",
    "PATH_TO_IMAGES_DIR = PATH_TO_DATABASE + 'img1/'\n",
    "PATH_TO_ANNOTATIONS_DIR = PATH_TO_DATABASE + '/gt/gt.txt'\n",
    "\n",
    "PATH_TO_OUTPUT_DIR = 'Output/'\n",
    "PATH_TO_PREDICTION_DIR = os.path.join(PATH_TO_OUTPUT_DIR, MODEL_NAME + '_MOT16_' + VIDEO_SEQ) # Output/Model_MOT16_01\n",
    "PREDICTION_PKL_FILE = os.path.join(PATH_TO_PREDICTION_DIR, \"prediction\")\n",
    "FILTERED_PKL_FILE = os.path.join(PATH_TO_PREDICTION_DIR, \"prediction_filtered\") # Filtered to only person class\n",
    "RESULT_CSV_FILE = os.path.join(PATH_TO_PREDICTION_DIR, \"dt.csv\") # Per frame per object id\n",
    "SUMMARY_CSV_FILE = os.path.join(PATH_TO_PREDICTION_DIR, \"summary.csv\") # Frame wise summary\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "# Store results to Output/Model directory\n",
    "if not os.path.exists(PATH_TO_PREDICTION_DIR):\n",
    "    os.makedirs(PATH_TO_PREDICTION_DIR)\n",
    "    os.makedirs(os.path.join(PATH_TO_PREDICTION_DIR,\"Image\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_np : np array of the image\n",
    "# prediction : prediction dictionary for the image\n",
    "# groundtruth : groundtruth dictionary for the image\n",
    "def visualize_image(image_np, prediction=None, groundtruth=None, isIDMode=False):\n",
    "    if isIDMode and prediction != None:\n",
    "        # Plot the prediction\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          prediction['detection_boxes'],\n",
    "          prediction['person_id'], #prediction['detection_classes'],\n",
    "          prediction['detection_scores'],\n",
    "          pc_label, #category_index,\n",
    "          instance_masks=prediction.get('detection_masks'),\n",
    "          use_normalized_coordinates=False,\n",
    "          min_score_thresh=0.30,\n",
    "          line_thickness=8)\n",
    "        return\n",
    "        \n",
    "    if prediction != None:\n",
    "        # Plot the prediction\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          prediction['detection_boxes'],\n",
    "          prediction['detection_classes'],\n",
    "          prediction['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=prediction.get('detection_masks'),\n",
    "          use_normalized_coordinates=False,\n",
    "          min_score_thresh=0.30,\n",
    "          line_thickness=8)\n",
    "    \n",
    "    if groundtruth != None:\n",
    "        # Plot the ground truth\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          groundtruth['groundtruth_boxes'],\n",
    "          groundtruth['groundtruth_classes'],\n",
    "          None,\n",
    "          category_index,\n",
    "          instance_masks=groundtruth.get('detection_masks'),\n",
    "          use_normalized_coordinates=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path : file name with extension E.g: 00010.jpg\n",
    "# prediction : prediction dictionary of the image\n",
    "def drawBB(image_path, prediction, isIDMode=False):\n",
    "    # Visualization of the results of a detection.\n",
    "    original_image_path = os.path.join(PATH_TO_IMAGES_DIR, image_path)   \n",
    "    marked_image_path = os.path.join(PATH_TO_PREDICTION_DIR, 'Image')\n",
    "    marked_image_path = os.path.join(marked_image_path, image_path) \n",
    "\n",
    "    image = Image.open(original_image_path)\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Update the image with predicted and groundtruth BB\n",
    "    #visualize_image(image_np, groundtruth=prediction)\n",
    "    visualize_image(image_np, prediction=prediction, isIDMode=isIDMode)    \n",
    "    im = Image.fromarray(image_np)\n",
    "    IMAGE_FILE = os.path.join(marked_image_path)\n",
    "    #print \"Save file in\" + IMAGE_FILE\n",
    "    im.save(IMAGE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract groundtruth from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV text-file containing one object instance per line. Each line must contain 10 values: \n",
    "# <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>, <conf>, <x>, <y>, <z> \n",
    "# All frame numbers, target IDs and bounding boxes are 1-based\n",
    "# Frame number is image number without leading 0\n",
    "# Person ID is <id>\n",
    "\n",
    "def extract_gt():\n",
    "    gt = 0\n",
    "    with open(PATH_TO_ANNOTATIONS_DIR, 'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            print ', '.join(row)\n",
    "            groundtruth = {}\n",
    "            gt_bbs = []\n",
    "            cat_label = []\n",
    "            \n",
    "            # For each BB in each image\n",
    "            gt_bb = []\n",
    "            gt_bb.append( float(row[3]) + float(row[5])  ) # ymin # bb_top - bb_height\n",
    "            gt_bb.append( float(row[2]) ) # xmin # bb_left\n",
    "            gt_bb.append( float(row[3]) ) # ymax # bb_top\n",
    "            gt_bb.append( float(row[2]) + float(row[4]) ) # xmax # bb_left + bb_width\n",
    "            \n",
    "            gt_bbs.append(gt_bb)\n",
    "            cat_label.append(str(category_index[1]['name']))\n",
    "            print cat_label\n",
    "            groundtruth['filename'] = row[1].zfill(6) + '.jpg'\n",
    "            groundtruth['groundtruth_boxes'] = np.array(gt_bbs, dtype=\"float32\")\n",
    "            groundtruth['groundtruth_classes'] = np.array(cat_label)\n",
    "\n",
    "            return groundtruth\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unroll the prediction BB as multiple row\n",
    "#<frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>, <conf>, <x>, <y>, <z>\n",
    "def appendMatching(image_id, prediction):\n",
    "    # Result per frame per object\n",
    "    for i in range(prediction['num_detections']):\n",
    "        row = []\n",
    "        # ID\n",
    "        row.append(prediction['person_id'][i])\n",
    "        # bb_left\n",
    "        row.append(prediction['detection_boxes'][i][1])\n",
    "        # bb_top\n",
    "        row.append(prediction['detection_boxes'][i][2])\n",
    "        # bb_width\n",
    "        row.append(prediction['detection_boxes'][i][3] - row[2])\n",
    "        # bb_height\n",
    "        row.append(row[3] - prediction['detection_boxes'][i][0] )\n",
    "        row = ','.join(map(str,row))\n",
    "\n",
    "        # Frame number\n",
    "        row = image_id + ',' + row + '\\n'\n",
    "        with open(RESULT_CSV_FILE,'a') as fd:\n",
    "            fd.write(row)\n",
    "    \n",
    "    # Summary per frame\n",
    "    # <frame_id> <total_objects> <entry object> <exited object> <same object>\n",
    "    # Total object is this frame\n",
    "    # cnt of objects entered / detected first time wrt prev frame\n",
    "    # cnt of objects who left the frame wrt prev\n",
    "    \n",
    "    row = []\n",
    "    # total\n",
    "    row.append( prediction['num_detections'] )\n",
    "    # entry_cnt per frame\n",
    "    row.append( prediction['num_detections_entry'] )\n",
    "    # exit_cnt per frame\n",
    "    row.append( prediction['num_detections_exit'] )\n",
    "    # same\n",
    "    row.append( row[0] - row[1])\n",
    "    \n",
    "    row = ','.join(map(str, row))\n",
    "    row = image_id + ',' + row + '\\n'\n",
    "    with open(SUMMARY_CSV_FILE,'a') as fd:\n",
    "        fd.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching algo\n",
    "Data association via IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON_COUNTER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match objects between two frames and tag id to new objects\n",
    "def twoFrameMatching(pie, dt, gt):\n",
    "    dt, exit_cnt = pc_utils.matchOnIoU(pie, dt, gt)\n",
    "    entry_cnt = 0\n",
    "    # Assign id to unassigned detections\n",
    "    for i in range(dt['num_detections']):\n",
    "        if dt['person_id'][i] == -1:\n",
    "            global PERSON_COUNTER\n",
    "            PERSON_COUNTER += 1\n",
    "            global pc_label\n",
    "            pc_label[PERSON_COUNTER] = { 'id': PERSON_COUNTER, 'name' : 'PC'+ str(PERSON_COUNTER) }\n",
    "            dt['person_id'][i] = PERSON_COUNTER\n",
    "            entry_cnt = entry_cnt + 1\n",
    "    dt['num_detections_entry'] = entry_cnt\n",
    "    dt['num_detections_exit'] = exit_cnt\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGT(image_id, gt, initMode=False):\n",
    "    if initMode:\n",
    "        # Initialize the person counter\n",
    "        global PERSON_COUNTER\n",
    "        PERSON_COUNTER = 0\n",
    "        gt['person_id'] = np.array([i+1 for i in range(gt['num_detections'])])\n",
    "        # fill the pc label map\n",
    "        for i in range(gt['num_detections']):\n",
    "            global pc_label\n",
    "            pc_label[i] = { 'id': i, 'name' : 'PC'+ str(i)}\n",
    "\n",
    "    appendMatching(image_id, gt)\n",
    "    # Save first image\n",
    "    image_path = image_id + '.jpg'\n",
    "    drawBB(image_path, gt, isIDMode=True)\n",
    "    \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign ID to person detected \n",
    "def assignID():\n",
    "    if os.path.exists(RESULT_CSV_FILE):\n",
    "        os.remove(RESULT_CSV_FILE)\n",
    "    if os.path.exists(SUMMARY_CSV_FILE):\n",
    "        os.remove(SUMMARY_CSV_FILE)\n",
    "\n",
    "    with open(FILTERED_PKL_FILE,'rb') as fd:\n",
    "        ev_data = pickle.load(fd)\n",
    "\n",
    "    # Init per image evaluation\n",
    "    num_groundtruth_classes = 1\n",
    "    matching_iou_threshold = 0.5\n",
    "    nms_iou_threshold = 1.0\n",
    "    nms_max_output_boxes = 10000\n",
    "\n",
    "    pie = pc_utils.pc_PerImageEvaluation(num_groundtruth_classes, matching_iou_threshold, nms_iou_threshold,nms_max_output_boxes)\n",
    "\n",
    "    # First frame\n",
    "    frame_id = 1\n",
    "    image_id = str(frame_id).zfill(6)\n",
    "    gt = ev_data[image_id] # treated as gt\n",
    "    gt['num_detections_entry'] = gt['num_detections']\n",
    "    gt['num_detections_exit'] = 0\n",
    "    gt = makeGT(image_id, gt, initMode=True)\n",
    "   \n",
    "    # Next frame\n",
    "    image_id = str(frame_id+1).zfill(6)\n",
    "    dt = ev_data[image_id] # treated as dt\n",
    "\n",
    "    for frame_id in range(1,IMAGE_COUNT-1): # Upto last but one\n",
    "        # Returns gt for next\n",
    "        gt = twoFrameMatching(pie, dt, gt)\n",
    "        gt = makeGT(image_id, gt, initMode=False)\n",
    "        \n",
    "        # Prepare next loop\n",
    "        frame_id = frame_id + 1\n",
    "        image_id = str(frame_id+1).zfill(6)\n",
    "        dt = ev_data[image_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter prediction to only person class\n",
    "def filter_prediction():\n",
    "    print(PREDICTION_PKL_FILE)\n",
    "    with open(PREDICTION_PKL_FILE,'rb') as fd:\n",
    "        ev_data = pickle.load(fd)\n",
    "        # Need to sequentially analyse\n",
    "        for i in range(1,IMAGE_COUNT): # 655\n",
    "            # File name without extension\n",
    "            image_id = str(i).zfill(6)\n",
    "            prediction = ev_data[image_id]\n",
    "            # Person class = 1 in COCO dataset\n",
    "            idx = prediction['detection_classes'] == 1\n",
    "            prediction['num_detections'] = np.count_nonzero(idx)\n",
    "            prediction['detection_boxes'] = prediction['detection_boxes'][idx, :]\n",
    "            prediction['detection_scores'] = prediction['detection_scores'][idx]\n",
    "            prediction['detection_classes'] = prediction['detection_classes'][idx]\n",
    "            print \"Image\", image_id, \"dt\", prediction['num_detections']\n",
    "        # Store in pickle\n",
    "        with open(FILTERED_PKL_FILE,'wb') as fd2:\n",
    "            pickle.dump(ev_data, fd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total person 7705\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #filter_prediction()\n",
    "    assignID()\n",
    "    print \"Total person\", PERSON_COUNTER\n",
    "    print \"Done\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
